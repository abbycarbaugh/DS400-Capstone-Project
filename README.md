# DS400-Capstone-Project

Facial expressions are a vital part of human communication, and for most people, recognizing them is second nature. For individuals with autism and others in the community, however, may have a more difficult time recognizing and comprehending these expressions. To help individuals overcome this challenge, the project aims to develop a deep neural network model that can accurately recognize facial expressions. In order to achieve this, a dataset containing photos of people with different expressions that will be used to train and test the model. This dataset includes images with a variety of expressions, including happy, sad, angry,  surprised, neutral, fear and disgust. Once the model is trained and optimized, it will be integrated into an application that can analyze personal photos and precisely predict the facial expression in the image. This will provide a valuable tool for those with autism and those in the community to better understand the emotions of those around them. This application could also be valuable in the psychology and education fields, where accurate recognition of facial expressions is crucial for understanding human behavior and interactions. Overall, this project has the potential to improve the lives of many individuals and contribute to the advancement of technology in various fields.

This project uses dataset from a Kaggle challenge, "Challenges in Representation Learning: Facial Recognition Challenge." The dataset contains 48x48 greyscale images of faces with different expressions. For this multiclass classification problem there are seven categories - angry, disgust, fear, happy, sad, surprise and neutral - that the expression can be classified as. 

Dataset link: https://www.kaggle.com/competitions/challenges-in-representation-learning-facial-expression-recognition-challenge
